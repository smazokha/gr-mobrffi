{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "51e5b88c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import cfo_utils\n",
    "from pathlib import Path\n",
    "from scipy.signal import resample_poly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eeeefe30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SESSION_NAME = \"2025-08-29_1\"\n",
    "# SESSION_NAME = \"2025-08-29_2\"\n",
    "# SESSION_NAME = \"2025-08-29_3\"\n",
    "# SESSION_NAME = \"2025-08-29_4\"\n",
    "\n",
    "# SESSION_NAME = \"2025-08-31_1\"\n",
    "# SESSION_NAME = \"2025-08-31_2\"\n",
    "# SESSION_NAME = \"2025-08-31_3\"\n",
    "# SESSION_NAME = \"2025-08-31_4\"\n",
    "# SESSION_NAME = \"2025-08-31_5\"\n",
    "\n",
    "SESSION_NAME = \"train_1\"\n",
    "# SESSION_NAME = \"train_2\"\n",
    "# SESSION_NAME = \"train_3\"\n",
    "\n",
    "PATH = Path(f\"/home/smazokha/Desktop/probe_captures_{SESSION_NAME}/\")\n",
    "PATH_OUT_1 = Path(f\"/home/smazokha/Downloads/home_dataset_alfa/node1-1_epoch_{SESSION_NAME}_01_raw.h5\")\n",
    "PATH_OUT_2 = Path(f\"/home/smazokha/Downloads/home_dataset_alfa/node1-1_epoch_{SESSION_NAME}_02_raw.h5\")\n",
    "\n",
    "# file_1_idx = 50\n",
    "# file_2_idx = 100\n",
    "\n",
    "file_1_idx = 1000\n",
    "file_2_idx = 1000\n",
    "\n",
    "DEVICES = [\n",
    "    (\"alfa_01\", 1.),\n",
    "    (\"alfa_03\", 3.),\n",
    "    (\"alfa_04\", 4.),\n",
    "    (\"alfa_05\", 5.),\n",
    "    (\"alfa_06\", 6.),\n",
    "    (\"alfa_07\", 7.),\n",
    "    (\"alfa_08\", 8.),\n",
    "    (\"alfa_09\", 9.),\n",
    "    (\"alfa_10\", 10.),\n",
    "    (\"alfa_11\", 11.),\n",
    "    (\"alfa_12\", 12.),\n",
    "    (\"alfa_13\", 13.)]\n",
    "\n",
    "# Suppose arr has shape (2001, 320), dtype=complex64\n",
    "# 20 Msps -> 25 Msps means upsample by 25, downsample by 20\n",
    "UPSAMPLE_FACTOR = 25\n",
    "DOWNSAMPLE_FACTOR = 20\n",
    "EPS = 1e-12 # guard for zero/near-zero power|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e4444d3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ('alfa_01', 1.0):\n",
      " * Normalization: False\n",
      " * Upsampling: True\n",
      " * CFO comp.: False\n",
      "Processing ('alfa_03', 3.0):\n",
      " * Normalization: False\n",
      " * Upsampling: True\n",
      " * CFO comp.: False\n",
      "Processing ('alfa_04', 4.0):\n",
      " * Normalization: False\n",
      " * Upsampling: True\n",
      " * CFO comp.: False\n",
      "Processing ('alfa_05', 5.0):\n",
      " * Normalization: False\n",
      " * Upsampling: True\n",
      " * CFO comp.: False\n",
      "Processing ('alfa_06', 6.0):\n",
      " * Normalization: False\n",
      " * Upsampling: True\n",
      " * CFO comp.: False\n",
      "Processing ('alfa_07', 7.0):\n",
      " * Normalization: False\n",
      " * Upsampling: True\n",
      " * CFO comp.: False\n",
      "Processing ('alfa_08', 8.0):\n",
      " * Normalization: False\n",
      " * Upsampling: True\n",
      " * CFO comp.: False\n",
      "Processing ('alfa_09', 9.0):\n",
      " * Normalization: False\n",
      " * Upsampling: True\n",
      " * CFO comp.: False\n",
      "Processing ('alfa_10', 10.0):\n",
      " * Normalization: False\n",
      " * Upsampling: True\n",
      " * CFO comp.: False\n",
      "Processing ('alfa_11', 11.0):\n",
      " * Normalization: False\n",
      " * Upsampling: True\n",
      " * CFO comp.: False\n",
      "Processing ('alfa_12', 12.0):\n",
      " * Normalization: False\n",
      " * Upsampling: True\n",
      " * CFO comp.: False\n",
      "Processing ('alfa_13', 13.0):\n",
      " * Normalization: False\n",
      " * Upsampling: True\n",
      " * CFO comp.: False\n"
     ]
    }
   ],
   "source": [
    "def plot_fft(frame, fs_hz):\n",
    "    \"\"\"\n",
    "    Plot FFT magnitude of a single complex IQ frame.\n",
    "\n",
    "    frame : 1D numpy array of complex samples\n",
    "    fs_hz : sampling rate in Hz\n",
    "    \"\"\"\n",
    "    N = len(frame)\n",
    "    spectrum = np.fft.fftshift(np.fft.fft(frame))\n",
    "    freqs = np.fft.fftshift(np.fft.fftfreq(N, d=1.0/fs_hz))\n",
    "    mag_db = 20 * np.log10(np.abs(spectrum) + 1e-12)\n",
    "\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(freqs, mag_db)\n",
    "    plt.xlabel(\"Frequency (Hz)\")\n",
    "    plt.ylabel(\"Magnitude (dB)\")\n",
    "    plt.title(\"FFT of frame\")\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "def read_file(device_name, upsample_on=False, normalize_on=False, compensate_cfo=False, demo_fft=False):\n",
    "    with h5py.File(PATH / f\"{device_name}.h5\", \"r\") as f:\n",
    "        print(f\" * Normalization: {normalize_on}\")\n",
    "        print(f\" * Upsampling: {upsample_on}\")\n",
    "        print(f\" * CFO comp.: {compensate_cfo}\")\n",
    "\n",
    "        # Retrieve data from the file\n",
    "        iq = np.array(f[\"iq\"])\n",
    "        rssi = np.array(f[\"rssi_dbm\"])\n",
    "\n",
    "        # Reformat the RSSI values (type and shape)\n",
    "        rssi = rssi.astype(np.float64).reshape(-1, 1)\n",
    "\n",
    "        # Extract I and Q values separately (shape N_frames Ã— N_samples)\n",
    "        iq_i = iq[:, :, 0].astype(np.float64)\n",
    "        iq_q = iq[:, :, 1].astype(np.float64)\n",
    "\n",
    "        # Create complex values\n",
    "        iq_comp = iq_i + 1j * iq_q\n",
    "\n",
    "        # Since our IQ values are integer-coded (int16), we must divide them by 32768\n",
    "        int_scale = 1 / 32768\n",
    "        iq_comp = iq_comp * int_scale\n",
    "\n",
    "        # Resample each frame to 25 Msps\n",
    "        if upsample_on:\n",
    "            _, n_samples = iq_comp.shape\n",
    "            out_len = int(n_samples * UPSAMPLE_FACTOR / DOWNSAMPLE_FACTOR)\n",
    "            iq_comp_resampled = np.zeros((iq_comp.shape[0], out_len), dtype=np.complex128)\n",
    "\n",
    "            for packet_i in range(iq_comp.shape[0]):\n",
    "                frame = resample_poly(\n",
    "                    iq_comp[packet_i, :],\n",
    "                    up=UPSAMPLE_FACTOR,\n",
    "                    down=DOWNSAMPLE_FACTOR\n",
    "                )\n",
    "\n",
    "                iq_comp_resampled[packet_i, :] = frame\n",
    "\n",
    "            iq_comp = iq_comp_resampled\n",
    "\n",
    "        # Normalize frames to unit average power\n",
    "        if normalize_on:\n",
    "            iq_comp_normalized = np.zeros(iq_comp.shape, dtype=np.complex128)\n",
    "\n",
    "            for packet_i in range(iq_comp.shape[0]):\n",
    "                frame = iq_comp[packet_i, :]\n",
    "\n",
    "                mean_power = np.mean(np.abs(frame) ** 2)\n",
    "                if mean_power > 0:\n",
    "                    frame = frame / np.sqrt(mean_power)\n",
    "\n",
    "                iq_comp_normalized[packet_i, :] = frame\n",
    "\n",
    "            iq_comp = iq_comp_normalized\n",
    "\n",
    "        # Compensate CFO\n",
    "        if compensate_cfo:\n",
    "            fs = 25_000_000 if upsample_on else 20_000_000\n",
    "            cfo_parts = cfo_utils.extract_data_cfo(iq_comp, fs_in=fs)\n",
    "            iq_comp = cfo_utils.compensate_cfo(iq_comp, cfo_parts, fs=fs)\n",
    "\n",
    "        # Quick FFT plot on first frame (20 Msps data)\n",
    "        if demo_fft:\n",
    "            fs = 25_000_000 if upsample_on else 20_000_000\n",
    "            plot_fft(frame=iq_comp[0, :], fs_hz=fs)\n",
    "\n",
    "        # Convert into interleaved float64 (real, imag)\n",
    "        iq_out = np.empty((iq_comp.shape[0], iq_comp.shape[1] * 2), dtype=np.float64)\n",
    "        iq_out[:, 0::2] = np.real(iq_comp)\n",
    "        iq_out[:, 1::2] = np.imag(iq_comp)\n",
    "\n",
    "        return [iq_out, rssi]\n",
    "    \n",
    "def write_file(path_out, iq, label, rssi):\n",
    "    with h5py.File(path_out, \"w\") as f:\n",
    "        f.create_dataset(\"data\", data=iq)\n",
    "        f.create_dataset(\"label\", data=label)\n",
    "        f.create_dataset(\"rssi\", data=rssi)\n",
    "\n",
    "iqs_1 = []\n",
    "rssis_1 = []\n",
    "labels_1 = []\n",
    "\n",
    "iqs_2 = []\n",
    "rssis_2 = []\n",
    "labels_2 = []\n",
    "\n",
    "# Run the merging process for each device (extract IQ, RSSI, Labels)\n",
    "for device in DEVICES:\n",
    "    print(f\"Processing {device}:\")\n",
    "    device_label = device[0]\n",
    "    device_id = device[1]\n",
    "    \n",
    "    iq, rssi = read_file(device_label, upsample_on=True, normalize_on=False, compensate_cfo=False, demo_fft=False)\n",
    "    label = np.full(iq.shape[0], device_id).reshape(-1, 1)\n",
    "    \n",
    "    iqs_1.append(iq[0:file_1_idx, :])\n",
    "    rssis_1.append(rssi[0:file_1_idx, :])\n",
    "    labels_1.append(label[0:file_1_idx, :])\n",
    "    \n",
    "    iqs_2.append(iq[file_1_idx:file_2_idx, :])\n",
    "    rssis_2.append(rssi[file_1_idx:file_2_idx, :])\n",
    "    labels_2.append(label[file_1_idx:file_2_idx, :])\n",
    "    \n",
    "# Merge it all into one set of objects\n",
    "iq_merged_1 = np.concatenate(iqs_1, axis=0)\n",
    "rssi_merged_1 = np.concatenate(rssis_1, axis=0)\n",
    "label_merged_1 = np.concatenate(labels_1, axis=0)\n",
    "\n",
    "iq_merged_2 = np.concatenate(iqs_2, axis=0)\n",
    "rssi_merged_2 = np.concatenate(rssis_2, axis=0)\n",
    "label_merged_2 = np.concatenate(labels_2, axis=0)\n",
    "\n",
    "# Write to H5 file\n",
    "write_file(PATH_OUT_1, iq_merged_1, label_merged_1, rssi_merged_1)\n",
    "write_file(PATH_OUT_2, iq_merged_2, label_merged_2, rssi_merged_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f370d234",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "00c4b5f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12000, 8190)\n"
     ]
    }
   ],
   "source": [
    "def keep_k_per_label(iq: np.ndarray, label: np.ndarray, rssi: np.ndarray, k: int):\n",
    "    \"\"\"\n",
    "    Keep at most k rows per label, preserving original order.\n",
    "    Works with label shaped (M,) or (M,1). Returns filtered (iq, label, rssi).\n",
    "    \"\"\"\n",
    "    lbl = np.ravel(label)  # (M,)\n",
    "    assert iq.shape[0] == lbl.shape[0] == rssi.shape[0], \"Mismatched lengths\"\n",
    "\n",
    "    counts = {}\n",
    "    mask = np.zeros(lbl.shape[0], dtype=bool)\n",
    "\n",
    "    for i, lab in enumerate(lbl):\n",
    "        c = counts.get(lab, 0)\n",
    "        if c < k:\n",
    "            mask[i] = True\n",
    "            counts[lab] = c + 1\n",
    "\n",
    "    return iq[mask], label[mask], rssi[mask]\n",
    "\n",
    "train_iq_1, train_label_1, train_rssi_1 = None, None, None\n",
    "train_iq_2, train_label_2, train_rssi_2 = None, None, None\n",
    "train_iq_3, train_label_3, train_rssi_3 = None, None, None\n",
    "\n",
    "with h5py.File(\"/home/smazokha/Downloads/home_dataset_alfa/node1-1_epoch_train_1_01_raw.h5\", \"r\") as f:\n",
    "    train_iq_1 = np.array(f['data'])\n",
    "    train_label_1 = np.array(f['label'])\n",
    "    train_rssi_1 = np.array(f['rssi'])\n",
    "\n",
    "    train_iq_1, train_label_1, train_rssi_1 = keep_k_per_label(train_iq_1, train_label_1, train_rssi_1, k = 500)\n",
    "\n",
    "with h5py.File(\"/home/smazokha/Downloads/home_dataset_alfa/node1-1_epoch_train_2_01_raw.h5\", \"r\") as f:\n",
    "    train_iq_2 = np.array(f['data'])\n",
    "    train_label_2 = np.array(f['label'])\n",
    "    train_rssi_2 = np.array(f['rssi'])\n",
    "\n",
    "    train_iq_2, train_label_2, train_rssi_2 = keep_k_per_label(train_iq_2, train_label_2, train_rssi_2, k = 500)\n",
    "\n",
    "# with h5py.File(\"/home/smazokha/Downloads/home_dataset_alfa/node1-1_epoch_train_03.h5\", \"r\") as f:\n",
    "#     train_iq_3 = np.array(f['data'])\n",
    "#     train_label_3 = np.array(f['label'])\n",
    "#     train_rssi_3 = np.array(f['rssi'])\n",
    "\n",
    "#     train_iq_3, train_label_3, train_rssi_3 = keep_k_per_label(train_iq_3, train_label_3, train_rssi_3, k = 500)\n",
    "\n",
    "train_iq_merged = np.concatenate([train_iq_1, train_iq_2], axis=0)\n",
    "train_label_merged = np.concatenate([train_label_1, train_label_2], axis=0)\n",
    "train_rssi_merged = np.concatenate([train_rssi_1, train_rssi_2], axis=0)\n",
    "\n",
    "print(train_iq_merged.shape)\n",
    "\n",
    "write_file(Path(\"/home/smazokha/Downloads/home_dataset_alfa/node1-1_epoch_train_merged_raw.h5\"), train_iq_merged, train_label_merged, train_rssi_merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc758482",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
